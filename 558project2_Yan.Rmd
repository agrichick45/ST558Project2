---
title: "project2_Yan"
author: "Yan Liu"
date: "2021/10/21"
output: 
   github_document:
    toc: true
    html_preview: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

Subset the data to work on the data channel of interest
```{r}
library(tidyverse)
library(caret)

data_whole<-read_csv("OnlineNewsPopularity/OnlineNewsPopularity.csv")

#create a new variable, channel, to help with the subsetting.
data_whole$channel <- names(data_whole[14:19])[apply(data_whole[14:19],1, match, x = 1)]
data_whole$channel <-sub("data_channel_is_", "", data_whole$channel)

#Subset the data to work on the data channel of interest
channel_interest = "lifestyle"

data_interest<-data_whole%>%
  filter(channel==channel_interest)%>%
  select(-c(1,14:19,62))
```


split the data into a training (70% of the data) and test set (30% of the data)
```{r}
library(rsample)
set.seed(14)
index <- initial_split(data_interest,
                       prop = 0.7)
train <- training(index)
test <- testing(index)
```

### Mandy's Graphical Summaries 


This graphical function looks at the correlation of all of the different variables against each other. 
```{r}
library(corrplot)
#drop values that are not important (the days of the week)
newTrain<-train[ -c(25:31) ]
#drop the predictor variables
predictTrain<-newTrain[ -c(47) ]
#Calculate the correlation Matrix and round it
res <- cor(predictTrain)
round(res, 2)

#Plot the correlation matrix values by cluster
corrplot(res, type = "upper", order = "hclust",
         tl.col = "black", tl.cex = 0.5)
```
From the results of this spot, it appears that we likely have some clusters of colinearity? How the self referencing scores (min, max, and average) are very much related. We likely can remove or pull these excess variables?


```{r}
#Holding this code for later
#palette = colorRampPalette(c("green", "white", "red")) (20)
#heatmap(x = res, col = palette, symm = TRUE, cexRow=0.5, cexCol = 0.5)
```


summarize the train data in tables and plots
=======
We summarize the train data of interest in tables grouped by weekdays, showing the pattern of shares in a week.

```{r}
#create a new variable, weekday, to help with the creating plots.
train$weekday <- names(train[25:31])[apply(train[25:31],1, match, x = 1)]
train$weekday <-sub("weekday_is_", "", train$weekday)

#summarize the train data by weekday.knitr::kable(
summary<-train%>%group_by(weekday)%>%
  summarise(Avg=round(mean(shares),0),Sd=round(sd(shares),0),Median=median(shares),IQR=round(IQR(shares),0))
knitr::kable(summary)
```
We summarize the train data of interest in the plots below. The histogram of shares shows that it is not a normal distribution.  After log transformation, the distribution of log(share) is more close to a normal distribution.
```{r}
#histogram of shares and log(shares).
hist(train$shares)
hist(log(train$shares))
```
We use box plots to show the difference in shares and images between weekday and weekend.
```{r}
#use boxplot to show the difference in the train data.
### try use y-axis on log-scale
### add boxplot of num_images
g1<-ggplot(train, aes(x=factor(is_weekend,labels=c("No", "Yes")),y=shares))
g1+geom_boxplot(fill="white", width=0.5,lwd=1.5,color='black',outlier.shape = NA)+
   scale_y_continuous(limits = quantile(train$shares, c(0.1, 0.9)))+
   labs(subtitle = "Shares on weekend",x="On weekend or not")

g1_log<-ggplot(train, aes(x=factor(is_weekend,labels=c("No", "Yes")),y=log(shares)))
g1_log+geom_boxplot(fill="white", width=0.5,lwd=1.5,color='black',outlier.shape = NA)+
   labs(subtitle = "Shares on weekend",x="On weekend or not")

g2<-ggplot(train, aes(x=factor(is_weekend,labels=c("No", "Yes")),y=num_imgs))
g2+geom_boxplot(fill="white", width=0.5,lwd=1.5,color='black',outlier.shape = NA)+
   scale_y_continuous(limits = quantile(train$num_imgs, c(0, 0.95)))+
   labs(subtitle = "number of images on weekend",x="On weekend or not")
```

We use scatter plot to show the relationship between share and num_imgs in the train data.
```{r}
g3<-ggplot(train,aes(x=num_imgs,y=shares))
g3+geom_point()+
  labs(subtitle = "num_imgs vs shares")+
  scale_y_continuous(limits = quantile(train$shares, c(0, 0.9)))+
  scale_x_continuous(limits = quantile(train$num_imgs, c(0, 0.9)))+
  geom_smooth(method="lm")

g4<-ggplot(train,aes(x=num_imgs,y=log(shares)))
g4+geom_point()+
  labs(subtitle = "num_imgs vs log(shares)")+
  scale_y_continuous(limits = quantile(log(train$shares), c(0, 0.9)))+
  scale_x_continuous(limits = quantile(train$num_imgs, c(0, 0.9)))+
  geom_smooth(method="lm")

#remove weekday from data set
train<-train%>%select(-weekday)

```

Models
# linear regression after log transformation
```{r}
lm<- lm(log(shares)~.,train)
summary(lm)
yhat_lm<-predict(lm,test[,-54])
RMSE_lm<-sqrt(mean((test$shares - exp(yhat_lm))^2))
```
# backward selection after log transformation
```{r}
#backward selection after log transformation
library(leaps)
backward<- regsubsets(log(shares)~., train, nvmax = 53, method = "backward")
backward_summary<-summary(backward)

#backward_summary[["which"]][size, ]
par(mfrow=c(2,3))
plot(backward_summary$cp, xlab = "Size", ylab = "backward Cp", type = "l")
plot(backward_summary$bic, xlab = "Size", ylab = "backward bic", type = "l")
plot(backward_summary$adjr2, xlab = "Size", ylab = "backward adjR2", type = "l")

coef(backward, which.min(backward_summary$cp))
coef(backward, which.max(backward_summary$adjr2))

#get best subset of the specified size with min cp.
sub <- backward_summary$which[which.min(backward_summary$cp), ]

# Create test model matrix, predcition, test error
test_model <- model.matrix(log(shares)~ ., data = test)
model <- test_model[, sub]
yhat_back<-model %*% coef(backward, which.min(backward_summary$cp))
RMSE_back<-sqrt(mean((test$shares - exp(yhat_back))^2))
```

try to tune the backward selection with train function
```{r}
cvcontrol <- trainControl(method="cv", number = 10)
grid <- expand.grid(nvmax=1:54)
train_back <- train(log(shares) ~ ., 
                   data=train,
                   method="leapBackward",
                   trControl=cvcontrol,
                   tuneLength = 50,
                   preProc = c("center", "scale"))
train_back$results
```

lasso after log transformation was not good. It delete all the variables...?
```{r}
library(glmnet)
x<-as.matrix(train[,-54])
y<-as.matrix(train[,54])
lasso <- cv.glmnet(x=x, y=log(y), alpha = 1)
lasso$lambda.1se
plot(lasso)

#refit the model with the whole dataset
lasso_all<- glmnet(x=x, y=log(y), 
                   alpha = 1)
predict(lasso_all, type = "coefficients", s = lasso$lambda.1se)
```

# boosted tree
```{r}

cvcontrol <- trainControl(method="repeatedcv", number = 10,
                          allowParallel=TRUE)
train_bstTree <- train(log(shares) ~ ., 
                   data=train,
                   method="bstTree",
                   
                   trControl=cvcontrol)
train_bstTree$results

grid <- expand.grid(n.trees = c(1000,1500), interaction.depth=c(1:3), shrinkage=c(0.01,0.05,0.1), n.minobsinnode=c(20))
capture.output(train.gbm <- train(log(shares) ~ ., 
                   data=train,
                   method="gbm",
                   trControl=cvcontrol,
                   tuneGrid = grid))
train.gbm$results
train.gbm$bestTune

#refit the train set with bestTune
library(gbm)
boostFit<-gbm(log(shares) ~ ., data=train,
              distribution="gaussian",
              shrinkage=0.01,
              interaction.depth=1,
              n.trees=1000,
              n.minobsinnode=20)
boostPred <- predict(boostFit, newdata = test[,-54], n.trees = 1000)
RMSE_boost <- sqrt(mean((test$shares - exp(boostPred))^2))
```

